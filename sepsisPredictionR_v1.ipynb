{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial steps\n",
    "1. File -> New -> Terminal\n",
    "2. In the terminal, type following commands\n",
    "        mkdir med264/\n",
    "        cd med264/\n",
    "        wget https://archive.physionet.org/users/shared/challenge-2019/training_setB.zip\n",
    "        unzip training_setB.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install & Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/home/aaron/R/x86_64-pc-linux-gnu-library/3.6’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.3     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.1     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.3     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.4.0     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "Installing package into ‘/home/aaron/R/x86_64-pc-linux-gnu-library/3.6’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 0.1.3 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom       \u001b[39m 0.7.6      \u001b[32m✔\u001b[39m \u001b[34mrsample     \u001b[39m 0.0.9 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials       \u001b[39m 0.0.9      \u001b[32m✔\u001b[39m \u001b[34mtune        \u001b[39m 0.1.5 \n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer       \u001b[39m 0.5.4      \u001b[32m✔\u001b[39m \u001b[34mworkflows   \u001b[39m 0.2.2 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata   \u001b[39m 0.1.0      \u001b[32m✔\u001b[39m \u001b[34mworkflowsets\u001b[39m 0.0.2 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip     \u001b[39m 0.1.5      \u001b[32m✔\u001b[39m \u001b[34myardstick   \u001b[39m 0.0.8 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mrecipes     \u001b[39m 0.1.16     \n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\u001b[34m•\u001b[39m Use \u001b[32mtidymodels_prefer()\u001b[39m to resolve common conflicts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dependencies  <- c(\"tidyverse\", \"tidymodels\", \"\")\n",
    "\n",
    "for (package in dependencies) { \n",
    "    library(package, character.only = TRUE)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "1. Load the list of files in the input directory\n",
    "2. Split the records to training and testing set\n",
    "3. Convert the data into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the input directory\n",
    "input_directory = 'training_setB'\n",
    "\n",
    "# Read all PSV files in the input directory and convert to a tibble\n",
    "all_data  <- list.files(path = input_directory, full.names = TRUE) %>% \n",
    "    .[grepl(\".psv\", .)] %>%\n",
    "    map(., read_delim, delim = \"|\", col_types = cols()) %>% \n",
    "    bind_rows() %>% \n",
    "    mutate(ID = row_number())\n",
    "\n",
    "# Split the data into training and testing set\n",
    "# 80% of data -> Training\n",
    "# 20% of data -> Testing\n",
    "\n",
    "train_all  <- slice_sample(all_data, prop = 0.8)\n",
    "\n",
    "test_all  <- all_data %>%\n",
    "    anti_join(train_all, by=\"ID\")\n",
    "\n",
    "train_labels  <- train_all[\"SepsisLabel\"]\n",
    "test_labels  <- test_all[\"SepsisLabel\"]\n",
    "\n",
    "train_data <- select(train_all, -c(\"SepsisLabel\", \"ID\"))\n",
    "test_data <- select(test_all, -c(\"SepsisLabel\", \"ID\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization of data\n",
    "1. Compute the mean and standard deviation of ONLY training set\n",
    "2. Use the statistics computed to standardize Training and Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean  <- colMeans(train_data, na.rm = TRUE)\n",
    "x_sd  <- apply(train_data, 2, sd, na.rm = TRUE)\n",
    "\n",
    "# For NaN entries, replace with 0\n",
    "# For the remaining entries, standardize with mean and std\n",
    "train_data <- sweep(train_data, 2, x_mean, \"-\") %>%\n",
    "    sweep(., 2, x_sd, \"/\")  %>%\n",
    "    `[<-`(., is.na(.), value = 0) %>% \n",
    "    cbind(train_labels)\n",
    "\n",
    "test_data <- sweep(test_data, 2, x_mean, \"-\") %>%\n",
    "    sweep(., 2, x_sd, \"/\") %>% \n",
    "    `[<-`(., is.na(.), value = 0) %>% \n",
    "    cbind(test_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "1. We will use a simple logistic regression model to model the data\n",
    "\n",
    "### Exercise 1\n",
    "1. Use a different penalty for Logistic Regression (LR) and plot the AUC curves\n",
    "2. Use a Support Vector Machine classifier instead of LR and plot the AUC curves\n",
    "3. Use a Random Forest Classifier instead of LR and plot the AUC curves \n",
    "\n",
    "        https://cran.r-project.org/web/packages/caret/caret.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: This engine requires some package installs: 'rstanarm'\n",
     "output_type": "error",
     "traceback": [
      "Error: This engine requires some package installs: 'rstanarm'\nTraceback:\n",
      "1. logistic_reg(penalty = 1, mixture = 0) %>% set_engine(\"stan\", \n .     iter = 150, algorithm = \"optimizing\") %>% set_mode(\"classification\") %>% \n .     fit(SepsisLabel ~ ., data = train_data)",
      "2. fit(., SepsisLabel ~ ., data = train_data)",
      "3. fit.model_spec(., SepsisLabel ~ ., data = train_data)",
      "4. check_installs(object)",
      "5. rlang::abort(glue::glue(\"This engine requires some package installs: \", \n .     glue::glue_collapse(glue::glue(\"'{missing_pkg}'\"), sep = \", \")))",
      "6. signal_abort(cnd)"
     ]
    }
   ],
   "source": [
    "model  <- logistic_reg(penalty = 1, mixture = 0) %>%  # Mixture=0 corresponds to Ridge Regression (L2) \n",
    "    set_engine(\"stan\", iter = 150, algorithm = \"optimizing\") %>% # Optimizing corresponds to LBFGS \n",
    "    set_mode(\"classification\") %>% \n",
    "    fit(SepsisLabel~., data = train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/home/aaron/R/x86_64-pc-linux-gnu-library/3.6’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "also installing the dependencies ‘V8’, ‘rstan’, ‘shinystan’\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"rstanarm\")\n",
    "library(rstanarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction\n",
    "1. Use the trained model to get output probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics\n",
    "1. Compute Area Under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot AUC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Interpretability\n",
    "\n",
    "Methods such as LIME [1], SHAP [2] allow for revealing the top features contributing to the predicted score at a local level. \n",
    "\n",
    "The python library SHAP (https://shap.readthedocs.io/en/latest/) uses the method of shapley values to determine the top contributing features.\n",
    "\n",
    "Use the python library SHAP and show the force plot, dependance plot and summary plot for each of the models developed above.\n",
    "Some examples using SHAP: https://shap.readthedocs.io/en/latest/examples.html\n",
    "\n",
    "[1] https://christophm.github.io/interpretable-ml-book/lime.html\n",
    "\n",
    "[2] https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
